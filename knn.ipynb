{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the important backages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  r'D:\\data science\\datasets\\pet\\images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do preprocessing on images by ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data = ImageDataGenerator ( `\n",
    "\n",
    "\n",
    ">rescale,->(if image  rescale to 0,1 instead of 0,255)`\n",
    "\n",
    " >rotation_range,->(support data veration, rotate data -20 ,20 degree)`\n",
    " \n",
    " \n",
    "  >width_shift_range ->(This allows the image to be shifted horizontally by a random amount up to 20%  )`\n",
    "  \n",
    "  \n",
    "   >height_shift_range,->(This allows the image to be shifted vertically by a random amount up to 20% )`\n",
    "   \n",
    "   \n",
    " >shear_range,->(This applies a random shear transformation (distortion or tilt) to the image. Shearing means changing the angle of the image)(bt4awahh el image 4oayaa)\n",
    "    \n",
    "    \n",
    ">zoom_range,->(This applies a random zoom in or out on the image by up to 20%)`\n",
    "    \n",
    "    \n",
    ">horizontal_flip,validation_split -> (if true , This means the images will be randomly flipped horizontally)`\n",
    "     \n",
    "     \n",
    ">validation_split -> (split data in to train and validation set 0.2 means 20% of data will be used for validation)`\n",
    "\n",
    "     ):\n",
    ">do things that will implement on tha data at the path that i will send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split = 0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i will split data into training and testing(validation) sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`use the generator (what is come from ImageDataGenerator)`\n",
    "\n",
    "\n",
    "`and implement flow_from_directory `\n",
    "\n",
    "\n",
    "`flow_from_directory( directory(my path to my data), target_size=(224, 224), batch_size=64, class_mode='categorical',subset='training')`\n",
    "\n",
    "\n",
    "`target_size -> size of each data i want to assigen (h,w)`\n",
    "\n",
    "\n",
    "`batch_size ->num of parts(set of images) i want to use in each iteration`\n",
    "\n",
    "\n",
    "`class_mode ->'categorical' represent that the data is categorical data`\n",
    "\n",
    "\n",
    "`(binary , categorical, sparse, integer, float, etc.)`\n",
    "\n",
    "\n",
    "`subset -> 'training' or 'validation'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5913 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = data.flow_from_directory (\n",
    "    path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    subset = 'training'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split to validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1477 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = data.flow_from_directory (\n",
    "    path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    subset = 'validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MobileNetV2 this is model in deep learning for feature extraction`\n",
    "\n",
    "\n",
    "`model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))`\n",
    "\n",
    "\n",
    "`weights = 'imagenet' ->  Loads the weights of the model pre-trained on the ImageNet dataset. This provides a strong foundation for feature extraction.`\n",
    ">because ImageNet dataset is a large dataset of images with 14 million images and 21,841 categories, so it is a good dataset for pre-training a model for feature extraction.\n",
    "\n",
    "\n",
    "`include_top=False ->  This argument is used to include or exclude the classification head of the model`\n",
    "\n",
    "\n",
    "`input_shape=(224, 224, 3) ->  Specifies the input shape of the model, which is 224x224 pixels with 3 color channels (RGB).`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract_model.trainable = False : freeze the weights of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_model = MobileNetV2(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "extract_model.trainable = False # freeze the layers(whights) to prevent overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction (data , extract_model):#extract_model-->MobileNetV2 model\n",
    "    feats = []\n",
    "    labels = []\n",
    "    for x_batch , y_batch in data:\n",
    "        feat_batch = extract_model.predict(x_batch) # implement the model on each patch\n",
    "        feats.append(feat_batch)\n",
    "        labels.append(y_batch)\n",
    "        if len(feats) >= len(data):\n",
    "            break\n",
    "    return np.vstack(feats), np.vstack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 903ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 870ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 841ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 788ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 849ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 793ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 824ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 944ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 880ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 787ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 803ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 866ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 781ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 863ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 892ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 806ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 866ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 886ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 879ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 923ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 910ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 772ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 812ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 836ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 965ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 867ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 792ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 828ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 845ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 858ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 835ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 849ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 860ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 820ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 826ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 862ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 832ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 840ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 839ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 860ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 878ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 895ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 826ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 845ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 890ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 822ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 851ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 806ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 799ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 787ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 836ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 882ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 841ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 889ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 811ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 830ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 849ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 862ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 873ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 896ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 968ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 944ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 948ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 948ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 893ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 887ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 859ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 874ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 924ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 944ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 843ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 840ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 854ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 939ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 854ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 825ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 825ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 804ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 835ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 910ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 894ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 845ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 929ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 823ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 786ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 802ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 792ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 850ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 786ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 827ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 963ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 904ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 804ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 903ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 851ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 868ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 826ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 931ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 785ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 850ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 904ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 864ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 903ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 853ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 863ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 922ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 883ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n"
     ]
    }
   ],
   "source": [
    "x_train , y_train = feature_extraction(train_data,extract_model)\n",
    "x_test , y_test = feature_extraction(test_data,extract_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Flatten the features`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.reshape(x_train.shape[0], -1)\n",
    "X_test = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`implement the KNN model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5\n",
    "knn = KNeighborsClassifier (n_neighbors = k ,metric = 'minkowski',p=2) # to perform euclidean\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_test: (1477, 2)\n",
      "Example of y_test: [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "Shape of y_pred: (1477, 2)\n",
      "Example of y_pred: [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "print(\"Example of y_test:\", y_test[:5])\n",
    "\n",
    "print(\"Shape of y_pred:\", y_pred.shape)\n",
    "print(\"Example of y_pred:\", y_pred[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_test and y_pred  both have the same shape which is One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "plt.figure(figsize=(3,2))\n",
    "sns.heatmap(cm,fmt = 'd',annot =True,cmap = 'Blues', xticklabels=range(2), yticklabels=range(2))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       476\n",
      "           1       0.97      0.97      0.97      1001\n",
      "\n",
      "    accuracy                           0.96      1477\n",
      "   macro avg       0.96      0.96      0.96      1477\n",
      "weighted avg       0.96      0.96      0.96      1477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962762356127285"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## if you want to input a new image and know what is it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarah\\AppData\\Local\\Temp\\ipykernel_17236\\214985324.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>implement the preprocessing on image</table><tr><td>1.path of image</td></tr><tr><td>2 and 3.resize image (from tensorflow.keras.preprocessing.image import load_img, img_to_array)</td></tr><tr><td>4.add batch dimension by using (np.expand_dims(arr,axis = position)) -> this is add new dimensional by add new group to this dimension -> this is important if you want to use this image in models in tensorflow and keras</td></tr><tr><td>5.Rescale if your model expects scaled input</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<table>implement the preprocessing on image</table><tr><td>1.path of image</td></tr><tr><td>2 and 3.resize image (from tensorflow.keras.preprocessing.image import load_img, img_to_array)</td></tr><tr><td>4.add batch dimension by using (np.expand_dims(arr,axis = position)) -> this is add new dimensional by add new group to this dimension -> this is important if you want to use this image in models in tensorflow and keras</td></tr><tr><td>5.Rescale if your model expects scaled input</td></tr></table>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### step1\n",
    ">implement the preprocessing on image\n",
    "\n",
    "\n",
    ">1.path of image\n",
    "\n",
    "\n",
    ">2 and 3.resize image (from tensorflow.keras.preprocessing.image import load_img, img_to_array)\n",
    "\n",
    "\n",
    ">4.add batch dimension by using (np.expand_dims(arr,axis = position)) -> this is add new dimensional by add new group to this dimension -> this is important if you want to use this image in models in tensorflow and keras\n",
    "\n",
    "\n",
    ">5.Rescale if your model expects scaled input\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
