{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the important backages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  r'D:\\data science\\datasets\\pet\\images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do preprocessing on images by ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data = ImageDataGenerator ( `\n",
    "\n",
    "\n",
    ">rescale,->(if image  rescale to 0,1 instead of 0,255)`\n",
    "\n",
    " >rotation_range,->(support data veration, rotate data -20 ,20 degree)`\n",
    " \n",
    " \n",
    "  >width_shift_range ->(This allows the image to be shifted horizontally by a random amount up to 20%  )`\n",
    "  \n",
    "  \n",
    "   >height_shift_range,->(This allows the image to be shifted vertically by a random amount up to 20% )`\n",
    "   \n",
    "   \n",
    " >shear_range,->(This applies a random shear transformation (distortion or tilt) to the image. Shearing means changing the angle of the image)(bt4awahh el image 4oayaa)\n",
    "    \n",
    "    \n",
    ">zoom_range,->(This applies a random zoom in or out on the image by up to 20%)`\n",
    "    \n",
    "    \n",
    ">horizontal_flip,validation_split -> (if true , This means the images will be randomly flipped horizontally)`\n",
    "     \n",
    "     \n",
    ">validation_split -> (split data in to train and validation set 0.2 means 20% of data will be used for validation)`\n",
    "\n",
    "     ):\n",
    ">do things that will implement on tha data at the path that i will send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split = 0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i will split data into training and testing(validation) sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`use the generator (what is come from ImageDataGenerator)`\n",
    "\n",
    "\n",
    "`and implement flow_from_directory `\n",
    "\n",
    "\n",
    "`flow_from_directory( directory(my path to my data), target_size=(224, 224), batch_size=64, class_mode='categorical',subset='training')`\n",
    "\n",
    "\n",
    "`target_size -> size of each data i want to assigen (h,w)`\n",
    "\n",
    "\n",
    "`batch_size ->num of parts(set of images) i want to use in each iteration`\n",
    "\n",
    "\n",
    "`class_mode ->'categorical' represent that the data is categorical data`\n",
    "\n",
    "\n",
    "`(binary , categorical, sparse, integer, float, etc.)`\n",
    "\n",
    "\n",
    "`subset -> 'training' or 'validation'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5913 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = data.flow_from_directory (\n",
    "    path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    subset = 'training'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split to validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1477 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = data.flow_from_directory (\n",
    "    path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    subset = 'validation',\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MobileNetV2 this is model in deep learning for feature extraction`\n",
    "\n",
    "\n",
    "`model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))`\n",
    "\n",
    "\n",
    "`weights = 'imagenet' ->  Loads the weights of the model pre-trained on the ImageNet dataset. This provides a strong foundation for feature extraction.`\n",
    ">because ImageNet dataset is a large dataset of images with 14 million images and 21,841 categories, so it is a good dataset for pre-training a model for feature extraction.\n",
    "\n",
    "\n",
    "`include_top=False ->  This argument is used to include or exclude the classification head of the model`\n",
    "\n",
    "\n",
    "`input_shape=(224, 224, 3) ->  Specifies the input shape of the model, which is 224x224 pixels with 3 color channels (RGB).`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract_model.trainable = False : freeze the weights of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_model = MobileNetV2(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "extract_model.trainable = False # freeze the layers(whights) to prevent overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction (data , extract_model):#extract_model-->MobileNetV2 model\n",
    "    feats = []\n",
    "    labels = []\n",
    "    for x_batch , y_batch in data:\n",
    "        feat_batch = extract_model.predict(x_batch) # implement the model on each patch\n",
    "        feats.append(feat_batch)\n",
    "        labels.append(y_batch)\n",
    "        if len(feats) >= len(data):\n",
    "            break\n",
    "    return np.vstack(feats), np.vstack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 987ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 977ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 993ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 965ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 953ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 904ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 990ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 978ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 967ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 920ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 833ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 972ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 956ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 983ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 963ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 952ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 939ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 838ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 981ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 961ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 788ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 810ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 900ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 743ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 856ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 960ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 962ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 751ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 819ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 935ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 970ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 992ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 974ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 963ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 955ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 948ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 917ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 972ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 921ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 908ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 990ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 942ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 997ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 989ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 961ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 867ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 844ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 878ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 883ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 920ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 869ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 896ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 857ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 988ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 966ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 903ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 940ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 934ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 936ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 960ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 902ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 975ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 919ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 943ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 946ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 934ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 868ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 984ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 761ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 783ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 906ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n"
     ]
    }
   ],
   "source": [
    "x_train , y_train = feature_extraction(train_data,extract_model)\n",
    "x_test , y_test = feature_extraction(test_data,extract_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Flatten the features`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.reshape(x_train.shape[0], -1)\n",
    "X_test = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`implement the KNN model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5\n",
    "knn = KNeighborsClassifier (n_neighbors = k ,metric = 'minkowski',p=2) # to perform euclidean\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_test: (1477, 2)\n",
      "Example of y_test: [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "Shape of y_pred: (1477, 2)\n",
      "Example of y_pred: [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "print(\"Example of y_test:\", y_test[:5])\n",
    "\n",
    "print(\"Shape of y_pred:\", y_pred.shape)\n",
    "print(\"Example of y_pred:\", y_pred[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_test and y_pred  both have the same shape which is One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "plt.figure(figsize=(3,2))\n",
    "sns.heatmap(cm,fmt = 'd',annot =True,cmap = 'Blues', xticklabels=['Cat','Dog'], yticklabels=['Cat','Dog'])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       476\n",
      "           1       0.97      0.98      0.97      1001\n",
      "\n",
      "    accuracy                           0.97      1477\n",
      "   macro avg       0.96      0.96      0.96      1477\n",
      "weighted avg       0.97      0.97      0.97      1477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965470548408937"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Generate synthetic dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Train KNN classifier\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# knn.fit(X_train, y_train)\n",
    "\n",
    "# # Predict probabilities\n",
    "# y_proba = knn.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "# # Compute ROC curve and AUC\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# # Plot the ROC curve\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "# plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Chance')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve for KNN Classifier')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.grid(alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## if you want to input a new image and know what is it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### step1\n",
    ">implement the preprocessing on image\n",
    "\n",
    "\n",
    ">1.path of image\n",
    "\n",
    "\n",
    ">2 and 3.resize image (from tensorflow.keras.preprocessing.image import load_img, img_to_array)\n",
    "\n",
    "\n",
    ">4.add batch dimension by using (np.expand_dims(arr,axis = position)) -> this is add new dimensional by add new group to this dimension -> this is important if you want to use this image in models in tensorflow and keras\n",
    "\n",
    "\n",
    ">5.Rescale if your model expects scaled input\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 1. Load and preprocess the image\n",
    "# img_path = r\"D:\\data science\\datasets\\pet\\Screenshot 2024-12-15 002205.png\" # Replace with the path to your image\n",
    "# img = image.load_img(img_path, target_size=(224, 224))  # Resize to match the input size\n",
    "# img_array = image.img_to_array(img)  # Convert the image to a NumPy array\n",
    "# img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "# img_array /= 255.0  # Rescale if your model expects scaled input (e.g., from ImageDataGenerator)\n",
    "\n",
    "# # 2. Extract features using the base model\n",
    "# features = extract_model.predict(img_array)  # Shape: (1, 7, 7, 1280)\n",
    "# features_flat = features.flatten().reshape(1, -1)  # Flatten and reshape for LogisticRegression\n",
    "\n",
    "# # 3. Predict the class using KNN\n",
    "# prediction = knn.predict(features_flat)  # Predict class index\n",
    "# class_index = prediction[0]  # Extract the predicted class index\n",
    "\n",
    "# # If `class_index` is still a numpy array, convert it to scalar\n",
    "# if isinstance(class_index, np.ndarray):\n",
    "#     class_index = class_index.item()\n",
    "\n",
    "# # 4. Map class index to class labels\n",
    "# class_labels = {0: 'Cat', 1: 'Dog'}  # Replace with your actual class labels\n",
    "# predicted_label = class_labels[class_index]\n",
    "\n",
    "# # 5. Display the result\n",
    "# plt.imshow(img)\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(f\"Predicted Class: {predicted_label}\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
